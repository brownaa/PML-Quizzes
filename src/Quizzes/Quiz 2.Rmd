---
title: "Quiz 2"
author: "Aaron Brown"
date: "April 28, 2016"
output: pdf_document
---

# Question 1  
```{r}
library(AppliedPredictiveModeling); require(caret)
data(AlzheimerDisease)

#1
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]

#2     Won't work because the data partition is resampled for training and test set
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)

#3
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)  #won't work; no list=FALSE argument
training = adData[trainIndex,]
testing = adData[-trainIndex,]

#4  no diagnosis variable
adData = data.frame(predictors)  
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
```

#Question 2  
```{r}
library(AppliedPredictiveModeling)
data(concrete)
library(caret); library(Hmisc)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]

training$NDX <- seq(1,nrow(training), 1)

ggplot(data = training) + aes(x = NDX, y = CompressiveStrength, 
                              colour = cut2(Cement)) + geom_point()
ggplot(data = training) + aes(x = NDX, y = CompressiveStrength, 
                              colour = cut2(BlastFurnaceSlag)) + geom_point()
ggplot(data = training) + aes(x = NDX, y = CompressiveStrength, 
                              colour = cut2(FlyAsh)) + geom_point()
ggplot(data = training) + aes(x = NDX, y = CompressiveStrength, 
                              colour = cut2(Water)) + geom_point()
ggplot(data = training) + aes(x = NDX, y = CompressiveStrength, 
                              colour = cut2(Superplasticizer)) + geom_point()
ggplot(data = training) + aes(x = NDX, y = CompressiveStrength, 
                              colour = cut2(CoarseAggregate)) + geom_point()
ggplot(data = training) + aes(x = NDX, y = CompressiveStrength, 
                              colour = cut2(FineAggregate)) + geom_point()
ggplot(data = training) + aes(x = NDX, y = CompressiveStrength, 
                              colour = cut2(Age)) + geom_point()

ggplot(data = training) + aes(x = FlyAsh, y = CompressiveStrength) + geom_point()
```
Answer: There is a non-random pattern in the plot of the outcome versus index that does not appear to be perfectly explained by any predictor suggesting a variable may be missing.

#Question 3  
```{r}
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]

hist(training$Superplasticizer)
hist(log(training$Superplasticizer +1))
```

Answer: There are a large number of values that are the same and even if you took the log(SuperPlasticizer + 1) they would still all be identical so the distribution would not be symmetric.

#Question 4  
```{r} 
##this is the principal component analysis techniques where we identify the number of
##principal components in order to capture 80% of the variance
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]

ILcols <- training[, grep("^IL", colnames(training))] #creates new DF with only IL cols

a4 <- preProcess(ILcols, method = 'pca', thresh = 0.8)

```

Answer: `r a4$numComp`

#Question 5  
```{r}
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]

trainingILcols <- training[, c(1,grep("^IL", colnames(training)))] #creates new DF with only IL cols
testingILcols  <- testing[, c(1,grep("^IL", colnames(testing)))] #creates new DF with only IL cols

##Pricipal Components Analysis
preProc <- preProcess(trainingILcols, method = "pca", thresh = 0.8)
trainPC <- predict(preProc, trainingILcols[,-1])
modelFitPC <- train(trainingILcols[,1] ~ ., method = "glm", data = trainPC)

testPC <- predict(preProc, testingILcols[,-1])
PCArslt <- confusionMatrix(testing[,1], predict(modelFitPC, testPC))
PCA.accuracy <- PCArslt[[3]][[1]]

modelFit <- train(trainingILcols[,1] ~ ., method = "glm", data = trainingILcols[,-1])
no.PCArslt <- confusionMatrix(testingILcols[,1], predict(modelFit, testingILcols[,-1]))
no.PCA.accuracy <- no.PCArslt[[3]][[1]]
```

Answer: Non-PCA accuracy: `r no.PCA.accuracy`  
            PCA accuracy: `r PCA.accuracy`